{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1RmgFtwcbGu"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"eurosat/rgb\"\n",
        "dataset, info = tfds.load(dataset_name, split=\"train\", as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "gvnGw5ZBdEjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_12th_per_class(dataset, num_classes, class_names):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    samples = {i: None for i in range(num_classes)}\n",
        "    counts = {i: 0 for i in range(num_classes)}\n",
        "\n",
        "    for image, label in dataset:\n",
        "        label_val = label.numpy()\n",
        "        counts[label_val] += 1\n",
        "\n",
        "        if counts[label_val] == 12:\n",
        "            samples[label_val] = (image, label)\n",
        "\n",
        "        if all(v is not None for v in samples.values()):\n",
        "            break\n",
        "\n",
        "    for i, (image, label) in enumerate(samples.values()):\n",
        "        plt.subplot(3, (num_classes + 2) // 3, i + 1)\n",
        "        plt.imshow(image.numpy())\n",
        "        plt.title(class_names[label.numpy()], fontsize=16)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_12th_per_class(dataset, len(class_names), class_names)"
      ],
      "metadata": {
        "id": "UEwJzc6UdElb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(info)"
      ],
      "metadata": {
        "id": "z1ZOE2hkdEnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = info.features[\"label\"].names\n",
        "print(\"EuroSAT Class Names:\")\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{i}: {name}\")"
      ],
      "metadata": {
        "id": "DCBSBzOodEpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(dataset))\n",
        "\n",
        "tensor_shape = tf.shape(image)\n",
        "\n",
        "print(f\"Shape of image: {tensor_shape}\")"
      ],
      "metadata": {
        "id": "gAMI0SfVdEry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(dataset)\n",
        "\n",
        "print(f\"Number of samples in the train dataset: {train_size}\")"
      ],
      "metadata": {
        "id": "ja4zOn6edEuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "6ZQTAWF3dUn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetV2S\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RoTZJLjudEwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "i6h0ML38dEyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.7 * total_size)  # 70% for training\n",
        "val_size = int(0.1 * total_size)    # 10% for validation\n",
        "test_size = total_size - train_size - val_size  # 20% for testing"
      ],
      "metadata": {
        "id": "26nOcRAXdE06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 27000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=False)"
      ],
      "metadata": {
        "id": "Lhkd6scJdE3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size).take(val_size)\n",
        "test_dataset = dataset.skip(train_size + val_size)"
      ],
      "metadata": {
        "id": "CBbjOSCTdE5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "9ZH3hlT_dE7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.2),\n",
        "    RandomZoom(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "P2C0Q0HFdE92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "train_dataset = test_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "val_dataset = val_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))"
      ],
      "metadata": {
        "id": "_ce7ZwzKdFAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetV2S(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(64, 64, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "0b62MBludFDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "wqo-zihadxe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "5IOfdQXjdxha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "BT-Vb_Pzdxju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "dcdTp8UpdxmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define Early Stopping Callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=5,          # Stop training if val_loss doesn't improve for 5 epochs\n",
        "    restore_best_weights=True  # Restore best model weights after stopping\n",
        ")"
      ],
      "metadata": {
        "id": "mTb8kKIMeUw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=20,callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "2o6DPHkVdxoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/modelEFFICIENTNETV2S.h5')"
      ],
      "metadata": {
        "id": "OADVMQ9hdxrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16.53, 11.69))\n",
        "ax1.plot(history.history['accuracy'])\n",
        "ax1.plot(history.history['val_accuracy'])\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('accuracy')\n",
        "ax1.set_title('Accuracy over epoch')\n",
        "ax1.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "ax2.plot(history.history['loss'])\n",
        "ax2.plot(history.history['val_loss'])\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.set_ylabel('loss')\n",
        "ax2.set_title('Loss over epoch')\n",
        "ax2.legend(['Train', 'Test'], loc=\"upper right\")"
      ],
      "metadata": {
        "id": "C5b1SRKOelPF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
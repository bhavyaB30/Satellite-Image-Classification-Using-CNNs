{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBdnvzCrVogW"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"eurosat/rgb\"\n",
        "dataset, info = tfds.load(dataset_name, split=\"train\", as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "eiz221QkW78O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(info)"
      ],
      "metadata": {
        "id": "Wg3vjZuWW8Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = info.features[\"label\"].names\n",
        "print(\"EuroSAT Class Names:\")\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{i}: {name}\")"
      ],
      "metadata": {
        "id": "fxx3WKWJW8Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_12th_per_class(dataset, num_classes, class_names):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    samples = {i: None for i in range(num_classes)}\n",
        "    counts = {i: 0 for i in range(num_classes)}\n",
        "\n",
        "    for image, label in dataset:\n",
        "        label_val = label.numpy()\n",
        "        counts[label_val] += 1\n",
        "\n",
        "        if counts[label_val] == 12:\n",
        "            samples[label_val] = (image, label)\n",
        "\n",
        "        if all(v is not None for v in samples.values()):\n",
        "            break\n",
        "\n",
        "    for i, (image, label) in enumerate(samples.values()):\n",
        "        plt.subplot(3, (num_classes + 2) // 3, i + 1)\n",
        "        plt.imshow(image.numpy())\n",
        "        plt.title(class_names[label.numpy()], fontsize=16)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_12th_per_class(dataset, len(class_names), class_names)"
      ],
      "metadata": {
        "id": "qoEofRrPW8Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(dataset))\n",
        "\n",
        "tensor_shape = tf.shape(image)\n",
        "\n",
        "print(f\"Shape of image: {tensor_shape}\")"
      ],
      "metadata": {
        "id": "3xKDuY_LW8KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(dataset)\n",
        "\n",
        "print(f\"Number of samples in the train dataset: {train_size}\")"
      ],
      "metadata": {
        "id": "RGcD8TNMW8NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "NdFAYP0EW8Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bynzdD8IW8Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "b8Xkp2rLW8Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.ResNet101(\n",
        "    weights=None,\n",
        "    include_top=False,\n",
        "    input_shape=(64, 64, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "WK2b7M8kW8a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "TPiKLCzmW8d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "output_layer = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=output_layer)"
      ],
      "metadata": {
        "id": "_FW3y1ESXj4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "# Compile the model with correct metrics\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "\n",
        "    metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "hTv8-QBsXj6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "18U6gTECXj8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.7 * total_size)  # 70% for training\n",
        "val_size = int(0.1 * total_size)    # 10% for validation\n",
        "test_size = total_size - train_size - val_size  # 20% for testing"
      ],
      "metadata": {
        "id": "dcIrGBG7Xj-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 27000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=False)\n",
        "train_ds = dataset.take(train_size)\n",
        "val_ds = dataset.skip(train_size).take(val_size)\n",
        "test_ds = dataset.skip(train_size + val_size)"
      ],
      "metadata": {
        "id": "7kIggDNsXkA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "sTFaYdc5XkET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.2),\n",
        "    RandomZoom(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "cA2w1fQyX1il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "val_dataset = val_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "test_dataset = test_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))"
      ],
      "metadata": {
        "id": "prtYIuHnX1lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True  # This restores the best weights automatically\n",
        ")"
      ],
      "metadata": {
        "id": "BZoGJwPnX1nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=20,callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "PnEWcYzhX1p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/modelRESNET101RUN4.h5')"
      ],
      "metadata": {
        "id": "tE6b-Z6dX1sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16.53, 11.69))\n",
        "ax1.plot(history.history['accuracy'])\n",
        "ax1.plot(history.history['val_accuracy'])\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('accuracy')\n",
        "ax1.set_title('Accuracy over epoch')\n",
        "ax1.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "ax2.plot(history.history['loss'])\n",
        "ax2.plot(history.history['val_loss'])\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.set_ylabel('loss')\n",
        "ax2.set_title('Loss over epoch')\n",
        "ax2.legend(['Train', 'Test'], loc=\"upper right\")"
      ],
      "metadata": {
        "id": "GrV56750X1uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WOrDLEMQX1yK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZur_x7x2QIX",
        "outputId": "6efbe876-84b8-464f-c379-bb4c52968c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"eurosat/rgb\"\n",
        "dataset, info = tfds.load(dataset_name, split=\"train\", as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "xYLV4DwpbRE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(info)"
      ],
      "metadata": {
        "id": "Kk3sfOVmbRIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = info.features[\"label\"].names\n",
        "print(\"EuroSAT Class Names:\")\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{i}: {name}\")"
      ],
      "metadata": {
        "id": "PEUcpyFUbRLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_12th_per_class(dataset, num_classes, class_names):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    samples = {i: None for i in range(num_classes)}\n",
        "    counts = {i: 0 for i in range(num_classes)}\n",
        "\n",
        "    for image, label in dataset:\n",
        "        label_val = label.numpy()\n",
        "        counts[label_val] += 1\n",
        "\n",
        "        if counts[label_val] == 12:\n",
        "            samples[label_val] = (image, label)\n",
        "\n",
        "        if all(v is not None for v in samples.values()):\n",
        "            break\n",
        "\n",
        "    for i, (image, label) in enumerate(samples.values()):\n",
        "        plt.subplot(3, (num_classes + 2) // 3, i + 1)\n",
        "        plt.imshow(image.numpy())\n",
        "        plt.title(class_names[label.numpy()], fontsize=16)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_12th_per_class(dataset, len(class_names), class_names)"
      ],
      "metadata": {
        "id": "cCzD-7_DbRON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(dataset))\n",
        "\n",
        "tensor_shape = tf.shape(image)\n",
        "\n",
        "print(f\"Shape of image: {tensor_shape}\")"
      ],
      "metadata": {
        "id": "y-rabK0ubRRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(dataset)\n",
        "\n",
        "print(f\"Number of samples in the train dataset: {train_size}\")"
      ],
      "metadata": {
        "id": "OoslKaS2bRUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "rN6PM4AybRXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M47Ai_s8bRdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121"
      ],
      "metadata": {
        "id": "ERmReLXUbRge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = DenseNet121(\n",
        "    weights=None,\n",
        "    include_top=False,\n",
        "    input_shape=(64, 64, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "YmZL2vusbRjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "YGXZqedXbu2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Resizing, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "yWoiFcojbu5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Db6CeyyXbu7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "UmpocUJcbu9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_size = int(0.7 * total_size)  # 70% for training\n",
        "val_size = int(0.1 * total_size)    # 10% for validation\n",
        "test_size = total_size - train_size - val_size  # 20% for testing"
      ],
      "metadata": {
        "id": "n6hNoY68bu_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 27000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=False)\n",
        "train_ds = dataset.take(train_size)\n",
        "val_ds = dataset.skip(train_size).take(val_size)\n",
        "test_ds = dataset.skip(train_size + val_size)"
      ],
      "metadata": {
        "id": "7YsDfXgbbvCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Smwh-bNIbvFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.2),\n",
        "    RandomZoom(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "YvmFcVuBbvIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "train_dataset = test_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "val_dataset = val_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))"
      ],
      "metadata": {
        "id": "BNqhRIZCcEPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define Early Stopping Callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=5,          # Stop training if val_loss doesn't improve for 5 epochs\n",
        "    restore_best_weights=True  # Restore best model weights after stopping\n",
        ")"
      ],
      "metadata": {
        "id": "4emsK5bWcER0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=20,callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "jKbXyL09cEUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/modelDENSENET121.h5')"
      ],
      "metadata": {
        "id": "0gEMn4KjcEYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16.53, 11.69))\n",
        "ax1.plot(history.history['accuracy'])\n",
        "ax1.plot(history.history['val_accuracy'])\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('accuracy')\n",
        "ax1.set_title('Accuracy over epoch')\n",
        "ax1.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "ax2.plot(history.history['loss'])\n",
        "ax2.plot(history.history['val_loss'])\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.set_ylabel('loss')\n",
        "ax2.set_title('Loss over epoch')\n",
        "ax2.legend(['Train', 'Test'], loc=\"upper right\")"
      ],
      "metadata": {
        "id": "zyy_t0ETcRK5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}